# NLP Paper Reproducibility Study
Assignment for Natural Language Processing course (part of MSc in Data and Web Science) at Aristotle University of Thessaloniki. 
Reproducibility study on paper:
BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation.

This repository does not include the code used by the authors for their paper. The authors' repository is publicly available at: 
https://github.com/txsun1997/metric-fairness

This repository only includes Jupyter notebooks that rerun their scripts and scripts or files that needed modifications. For reprodicibility, the reader should use our notebooks along with the authors' code and instructions. For more information on how to run our notebooks, please read our README.md files included in the uploaded folders.

We were not able to reproduce the exact results presented in the paper regarding the mitigation of bias with adapters, due to the large size of the datasets used and our limited resources. However, we managed to run their code and train the debiasing adapters for smaller datasets. The datasets used, and the trained adapters can be found at:
https://drive.google.com/drive/folders/1GqRgFSswPK7O250DZiFEU1grGzN8UBUk?usp=sharing

For more information on our reproducibility study, check our report: [RE]BERTScore_is_Unfair.pdf



